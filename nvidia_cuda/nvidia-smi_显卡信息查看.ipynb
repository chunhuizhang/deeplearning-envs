{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97880c4b",
   "metadata": {},
   "source": [
    "```\n",
    "!pip install nvidia-ml-py3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f22a8ef",
   "metadata": {},
   "source": [
    "- SMI: system management Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9630a447",
   "metadata": {},
   "source": [
    "## basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2893f435",
   "metadata": {},
   "source": [
    "- `nvcc -V`\n",
    "    - 这里显示的 cuda 版本，很可能与 `nvidia-smi` 显示的版本不一致"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fc65eb",
   "metadata": {},
   "source": [
    "```\n",
    "nvidia-smi --query-gpu=gpu_name,gpu_bus_id,vbios_version,compute_cap --format=csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9bd72fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:05:07.589721Z",
     "start_time": "2024-02-12T10:05:07.425257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name, pci.bus_id, vbios_version, compute_cap\r\n",
      "NVIDIA GeForce RTX 4090, 00000000:18:00.0, 95.02.3C.00.99, 8.9\r\n",
      "NVIDIA GeForce RTX 4090, 00000000:8A:00.0, 95.02.3C.00.99, 8.9\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=gpu_name,gpu_bus_id,vbios_version,compute_cap --format=csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8fb076-1885-48e1-aa26-ea1e63e26df6",
   "metadata": {},
   "source": [
    "### device id（设备编号）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e01adaf-f25a-4be6-8e72-869294408915",
   "metadata": {},
   "source": [
    "- https://blog.csdn.net/sdnuwjw/article/details/111615052\n",
    "    - nvidia-smi 下的 GPU 编号默认使用 PCI_BUS_ID，而 PyTorch 代码默认情况下设备排序是 FASTEST_FIRST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff6ce836-f223-48d9-8e2b-19b17811519d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:48:56.591151Z",
     "iopub.status.busy": "2024-07-19T11:48:56.590516Z",
     "iopub.status.idle": "2024-07-19T11:48:56.748102Z",
     "shell.execute_reply": "2024-07-19T11:48:56.745775Z",
     "shell.execute_reply.started": "2024-07-19T11:48:56.591103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 4090 (UUID: GPU-3aea0781-60bd-0145-884f-dcea78424adb)\n",
      "GPU 1: NVIDIA GeForce RTX 4090 (UUID: GPU-3c7f0ec9-c4bd-0098-3e5b-2169faec6f6c)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75356910-b92f-416e-919c-2a753c548e35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:49:33.921659Z",
     "iopub.status.busy": "2024-07-19T11:49:33.921053Z",
     "iopub.status.idle": "2024-07-19T11:49:35.403859Z",
     "shell.execute_reply": "2024-07-19T11:49:35.401975Z",
     "shell.execute_reply.started": "2024-07-19T11:49:33.921612Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c86dcb99-da79-4311-b163-3508346e9538",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:49:49.998812Z",
     "iopub.status.busy": "2024-07-19T11:49:49.998237Z",
     "iopub.status.idle": "2024-07-19T11:49:50.100197Z",
     "shell.execute_reply": "2024-07-19T11:49:50.098599Z",
     "shell.execute_reply.started": "2024-07-19T11:49:49.998767Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_CudaDeviceProperties(name='NVIDIA GeForce RTX 4090', major=8, minor=9, total_memory=24217MB, multi_processor_count=128)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_properties(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26707aba-f5ca-4704-912e-0c7492afee23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:50:01.489956Z",
     "iopub.status.busy": "2024-07-19T11:50:01.489332Z",
     "iopub.status.idle": "2024-07-19T11:50:01.502494Z",
     "shell.execute_reply": "2024-07-19T11:50:01.500324Z",
     "shell.execute_reply.started": "2024-07-19T11:50:01.489909Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_CudaDeviceProperties(name='NVIDIA GeForce RTX 4090', major=8, minor=9, total_memory=24217MB, multi_processor_count=128)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_properties(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3abcb3",
   "metadata": {},
   "source": [
    "## xorg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf1fae",
   "metadata": {},
   "source": [
    "- `/usr/lib/xorg/Xorg`\n",
    "    - 指的是X.Org Server，这是Linux和UNIX系统上的图形服务器，负责处理图形显示。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8f3689",
   "metadata": {},
   "source": [
    "## nvlink"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d1b9ce",
   "metadata": {},
   "source": [
    "- 3090 与 A100 nvlink 可以通用；\n",
    "- 3090 只能两两相连\n",
    "    - 卡A只能跟卡B相连\n",
    "    - 卡A如果跟卡B相连，就不能再跟卡C相连\n",
    "- A100 可以4卡相连"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56eb90c",
   "metadata": {},
   "source": [
    "## pynvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbfc58ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-15T11:27:23.800124Z",
     "start_time": "2023-07-15T11:27:23.777283Z"
    },
    "execution": {
     "iopub.execute_input": "2024-07-19T11:56:55.083936Z",
     "iopub.status.busy": "2024-07-19T11:56:55.083300Z",
     "iopub.status.idle": "2024-07-19T11:56:55.094795Z",
     "shell.execute_reply": "2024-07-19T11:56:55.092544Z",
     "shell.execute_reply.started": "2024-07-19T11:56:55.083890Z"
    }
   },
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4375c677-37a4-42d9-8e72-d3a8675730ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:58:20.719542Z",
     "iopub.status.busy": "2024-07-19T11:58:20.718992Z",
     "iopub.status.idle": "2024-07-19T11:58:20.732086Z",
     "shell.execute_reply": "2024-07-19T11:58:20.729944Z",
     "shell.execute_reply.started": "2024-07-19T11:58:20.719499Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0 UUID: GPU-3aea0781-60bd-0145-884f-dcea78424adb\n",
      "GPU 1 UUID: GPU-3c7f0ec9-c4bd-0098-3e5b-2169faec6f6c\n"
     ]
    }
   ],
   "source": [
    "import pynvml\n",
    "# 初始化 NVML\n",
    "pynvml.nvmlInit()\n",
    "\n",
    "# 获取 GPU 数量\n",
    "device_count = pynvml.nvmlDeviceGetCount()\n",
    "\n",
    "# 遍历每个 GPU 并获取其 UUID\n",
    "for i in range(device_count):\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "    uuid = pynvml.nvmlDeviceGetUUID(handle)\n",
    "    print(f\"GPU {i} UUID: {uuid}\")\n",
    "pynvml.nvmlShutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bfc7408",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-15T11:36:56.568743Z",
     "start_time": "2023-07-15T11:36:56.563747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 2663 MB.\n"
     ]
    }
   ],
   "source": [
    "# 初始状况下的 base 显存占用\n",
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ca0f5c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-15T11:37:36.925692Z",
     "start_time": "2023-07-15T11:37:36.912218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 2663 MB.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# 此时 kernels 也会被 loaded\n",
    "torch.ones((1, 1)).to(\"cuda\")\n",
    "print_gpu_utilization()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
