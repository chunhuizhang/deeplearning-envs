{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dcc6562-fff3-4b4c-a186-2d53bf377b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "509259e9-87da-47ac-a6e8-f80b94c7fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install GPUtil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c269a5-dac4-432c-8b49-18b8aa441ab6",
   "metadata": {},
   "source": [
    "- references\n",
    "    - https://stackoverflow.com/questions/57496285/why-is-the-memory-in-gpu-still-in-use-after-clearing-the-object\n",
    "    - https://pytorch.org/blog/understanding-gpu-memory-1/\n",
    "    - https://pytorch.org/blog/understanding-gpu-memory-2/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7a2a98-e4c0-41d0-801a-8023e724e620",
   "metadata": {},
   "source": [
    "## basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2879e-ce51-4ee6-8ca3-5c29e6bbc238",
   "metadata": {},
   "source": [
    "- `with torch.no_grad():`\n",
    "- `torch.cuda.empty_cache()`: torch 相关\n",
    "    - `gc.collect()`：python 相关\n",
    "\n",
    "```\n",
    "for i, left in enumerate(dataloader):\n",
    "    print(i)\n",
    "    with torch.no_grad():\n",
    "        temp = model(left).view(-1, 1, 300, 300)\n",
    "    right.append(temp.to('cpu'))\n",
    "    del temp\n",
    "    torch.cuda.empty_cache()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aedab3aa-c2c5-4035-b2e8-9f6d467a5df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPUtil import showUtilization as gpu_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9bad240-d0b5-4866-ab24-00f2bc7cbf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "|  1 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0476caa-dc34-45b8-84d8-74368b2560a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_list = []\n",
    "for x in range(10):\n",
    "    tensor_list.append(torch.randn(10000000, 10).cuda())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd88cc7a-7f8e-4301-a1d1-1ff9deed227e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 17% |\n",
      "|  1 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b441452b-429c-4c0e-93fa-16697f749936",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tensor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d4e2eb-9abb-474a-bbc4-f549cae91b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 17% |\n",
      "|  1 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da383046-d4ad-4325-a8d1-63dc6ecf3e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d10d7bcb-8944-498e-bf54-ef807906a15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  2% |\n",
      "|  1 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "032a871f-afae-468d-a45d-0aa0d3a3aa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d54d7603-1168-4aaf-965d-6b0c8dc739c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "881"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "034d71c0-0df7-4241-a28d-7acbd01c9d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  2% |\n",
      "|  1 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "gpu_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32238f39-399c-4704-883c-c393bdb8ba86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## gc（garbage collection）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
