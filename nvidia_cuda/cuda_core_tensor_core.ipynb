{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daedf914-1254-4f4f-bc2b-5bff4a550194",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T10:26:00.837375Z",
     "iopub.status.busy": "2024-11-16T10:26:00.836618Z",
     "iopub.status.idle": "2024-11-16T10:26:00.852178Z",
     "shell.execute_reply": "2024-11-16T10:26:00.850859Z",
     "shell.execute_reply.started": "2024-11-16T10:26:00.837331Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68b53867-d56c-4247-8e20-26044d9aca73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T10:26:00.854563Z",
     "iopub.status.busy": "2024-11-16T10:26:00.853880Z",
     "iopub.status.idle": "2024-11-16T10:26:02.291856Z",
     "shell.execute_reply": "2024-11-16T10:26:02.289953Z",
     "shell.execute_reply.started": "2024-11-16T10:26:00.854522Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b33a4d-302d-40ca-b5ed-eba056ba2221",
   "metadata": {},
   "source": [
    "### tf32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9e1ef52-d0ba-40f4-b5a5-035ce6fbe5ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T10:26:02.293697Z",
     "iopub.status.busy": "2024-11-16T10:26:02.293379Z",
     "iopub.status.idle": "2024-11-16T10:26:02.305708Z",
     "shell.execute_reply": "2024-11-16T10:26:02.304004Z",
     "shell.execute_reply.started": "2024-11-16T10:26:02.293677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://api.ibos.cn/v4/weapparticle/accesswximg?aid=86367&url=aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9yY1Z1ZmlhVDAwVm5ZNTVQTnRnQ2dERVc0UzA5RVJKNERWSUtTRkZyRTZZOXVVUEFqQlJRTkpzc1owMjVjQUR2aFZvU2N5WVRJWnp3bFJnQnNKcmQ3bmcvNjQwP3d4X2ZtdD1wbmcmYW1w;from=appmsg\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://api.ibos.cn/v4/weapparticle/accesswximg?aid=86367&url=aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9yY1Z1ZmlhVDAwVm5ZNTVQTnRnQ2dERVc0UzA5RVJKNERWSUtTRkZyRTZZOXVVUEFqQlJRTkpzc1owMjVjQUR2aFZvU2N5WVRJWnp3bFJnQnNKcmQ3bmcvNjQwP3d4X2ZtdD1wbmcmYW1w;from=appmsg', width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba29187-8cb7-4308-af69-61db3ba71e7e",
   "metadata": {},
   "source": [
    "- bf16 的问题范围大，但精度小；\n",
    "- fp16 精度大，但范围小；\n",
    "- https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices\n",
    "    - TF32 tensor cores are designed to achieve better performance on matmul and convolutions on torch.float32 tensors by rounding input data to have **10 bits of mantissa**, and **accumulating results with FP32 precision**, maintaining FP32 dynamic range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32626fb5-750f-475f-9232-140ba5c820e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T10:26:02.306650Z",
     "iopub.status.busy": "2024-11-16T10:26:02.306436Z",
     "iopub.status.idle": "2024-11-16T10:26:02.326535Z",
     "shell.execute_reply": "2024-11-16T10:26:02.324974Z",
     "shell.execute_reply.started": "2024-11-16T10:26:02.306633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(5).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70860540-9c7c-4eca-9dcb-d4ef2477bcc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T10:26:02.327636Z",
     "iopub.status.busy": "2024-11-16T10:26:02.327421Z",
     "iopub.status.idle": "2024-11-16T10:26:02.334648Z",
     "shell.execute_reply": "2024-11-16T10:26:02.332941Z",
     "shell.execute_reply.started": "2024-11-16T10:26:02.327620Z"
    }
   },
   "outputs": [],
   "source": [
    "# Enable TF32 on CUDA\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6047384-9cf4-49cb-8c88-6267e29291f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T10:26:02.336815Z",
     "iopub.status.busy": "2024-11-16T10:26:02.336590Z",
     "iopub.status.idle": "2024-11-16T10:26:02.822200Z",
     "shell.execute_reply": "2024-11-16T10:26:02.820209Z",
     "shell.execute_reply.started": "2024-11-16T10:26:02.336799Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "randn() received an invalid combination of arguments - got (int, dtype=str), but expected one of:\n * (tuple of ints size, *, torch.Generator generator, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, torch.Generator generator, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtf32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdtype\n",
      "\u001b[0;31mTypeError\u001b[0m: randn() received an invalid combination of arguments - got (int, dtype=str), but expected one of:\n * (tuple of ints size, *, torch.Generator generator, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, torch.Generator generator, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n"
     ]
    }
   ],
   "source": [
    "torch.randn(5, dtype='tf32').dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2479ebd2-f2f2-49af-a1ad-359f06ae691b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T10:26:04.847275Z",
     "iopub.status.busy": "2024-11-16T10:26:04.846988Z",
     "iopub.status.idle": "2024-11-16T10:26:13.933302Z",
     "shell.execute_reply": "2024-11-16T10:26:13.932430Z",
     "shell.execute_reply.started": "2024-11-16T10:26:04.847256Z"
    }
   },
   "outputs": [],
   "source": [
    "a_full = torch.randn(10240, 10240*5, dtype=torch.double, device='cuda')\n",
    "b_full = torch.randn(10240*5, 10240, dtype=torch.double, device='cuda')\n",
    "ab_full = a_full @ b_full\n",
    "mean = ab_full.abs().mean()  # 80.7277"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66b3b2d1-3d86-4695-bb8c-fb12278959cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T10:26:15.860173Z",
     "iopub.status.busy": "2024-11-16T10:26:15.859985Z",
     "iopub.status.idle": "2024-11-16T10:26:15.871219Z",
     "shell.execute_reply": "2024-11-16T10:26:15.870492Z",
     "shell.execute_reply.started": "2024-11-16T10:26:15.860153Z"
    }
   },
   "outputs": [],
   "source": [
    "a = a_full.float()\n",
    "b = b_full.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22cb697d-0ba5-4ca8-8f00-672a5898b02a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T10:26:18.297741Z",
     "iopub.status.busy": "2024-11-16T10:26:18.297497Z",
     "iopub.status.idle": "2024-11-16T10:26:18.550815Z",
     "shell.execute_reply": "2024-11-16T10:26:18.549692Z",
     "shell.execute_reply.started": "2024-11-16T10:26:18.297724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0024, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do matmul at TF32 mode.\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "ab_tf32 = a @ b  # takes 0.016s on GA100\n",
    "error = (ab_tf32 - ab_full).abs().max()  # 0.1747\n",
    "relative_error = error / mean  # 0.0022\n",
    "relative_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b503d736-e2a2-470c-baac-9e2d7c75f698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T10:26:21.182132Z",
     "iopub.status.busy": "2024-11-16T10:26:21.181885Z",
     "iopub.status.idle": "2024-11-16T10:26:21.402362Z",
     "shell.execute_reply": "2024-11-16T10:26:21.401600Z",
     "shell.execute_reply.started": "2024-11-16T10:26:21.182116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.8293e-05, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do matmul with TF32 disabled.\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "ab_fp32 = a @ b  # takes 0.11s on GA100\n",
    "error = (ab_fp32 - ab_full).abs().max()  # 0.0031\n",
    "relative_error = error / mean  # 0.000039\n",
    "relative_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510cc7fa-766c-472b-8cd7-7a53bf748963",
   "metadata": {},
   "source": [
    "### Inference data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c323678-d21d-4594-8785-4c73e062ef45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
